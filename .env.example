# ============================================
# ServiceNow Configuration
# ============================================
SNOW_INSTANCE=your-instance.service-now.com
SNOW_CLIENT_ID=your-client-id
SNOW_CLIENT_SECRET=your-client-secret

# Optional: Basic Auth (not recommended, use OAuth above)
# SNOW_USERNAME=your-username
# SNOW_PASSWORD=your-password

# ============================================
# LLM Provider Selection (for OpenCode)
# ============================================

# Choose your default LLM provider
# Options: anthropic, openai, google, azure, cohere, mistral, groq, openrouter, ollama, perplexity
DEFAULT_LLM_PROVIDER=anthropic

# Default models per provider (uncomment the one you're using)
DEFAULT_ANTHROPIC_MODEL=claude-sonnet-4                    # Best for complex reasoning
DEFAULT_OPENAI_MODEL=gpt-4o                                # General purpose
DEFAULT_GOOGLE_MODEL=gemini-1.5-pro                        # Large context (2M tokens)
DEFAULT_AZURE_MODEL=gpt-4o                                 # Enterprise OpenAI
DEFAULT_COHERE_MODEL=command-r-plus                        # Enterprise AI
DEFAULT_MISTRAL_MODEL=mistral-large-latest                 # European AI
DEFAULT_GROQ_MODEL=llama-3.1-70b-versatile                 # Ultra-fast inference
DEFAULT_PERPLEXITY_MODEL=llama-3.1-sonar-large-128k-online # Web search enabled
DEFAULT_OLLAMA_MODEL=llama3.1                              # Local/offline

# ============================================
# üåü TIER 1: Premium Providers (Best Quality)
# ============================================

# ü§ñ Anthropic (Claude) - Best for complex ServiceNow logic
#
# Option 1: Use your Claude Pro/Max subscription (recommended if you have one)
# - No API key needed! OpenCode will prompt you to log in with Anthropic
# - Uses your existing Claude Pro ($20/month) or Claude Max ($40/month)
# - Leave ANTHROPIC_API_KEY empty and run: opencode (then log in when prompted)
#
# Option 2: Pay-per-use API
# - Pricing: $3/$15 per 1M tokens (input/output)
# - Get API key: https://console.anthropic.com/
# - Add your key below:
ANTHROPIC_API_KEY=

# üß† OpenAI (GPT) - General purpose, excellent quality
# Pricing: $2.50/$10 per 1M tokens (gpt-4o)
# Get API key: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# üî∑ Azure OpenAI - Enterprise OpenAI with SLA
# Pricing: Similar to OpenAI, billed through Azure
# Setup: https://azure.microsoft.com/en-us/products/ai-services/openai-service
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

# ============================================
# üöÄ TIER 2: High Performance Providers
# ============================================

# üîç Google AI (Gemini) - Massive context window (2M tokens)
# Pricing: $1.25/$5 per 1M tokens
# Get API key: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# üåê Perplexity - Web search enabled models
# Pricing: $1/$5 per 1M tokens (sonar models)
# Get API key: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=

# ‚ö° Groq - Ultra-fast inference (70+ tokens/sec)
# Pricing: FREE for now (rate limited)
# Get API key: https://console.groq.com/keys
GROQ_API_KEY=

# ============================================
# üí∞ TIER 3: Cost-Effective Providers
# ============================================

# üîÄ OpenRouter - Access to 200+ models with unified API
# Pricing: Varies by model (pass-through pricing)
# Get API key: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# üá™üá∫ Mistral AI - European AI provider
# Pricing: $2/$6 per 1M tokens (mistral-large)
# Get API key: https://console.mistral.ai/api-keys
MISTRAL_API_KEY=

# üè¢ Cohere - Enterprise AI with multilingual support
# Pricing: $1/$2 per 1M tokens (command-r-plus)
# Get API key: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=

# ============================================
# üè† TIER 4: Local/Offline Providers (FREE)
# ============================================

# ü¶ô Ollama - Run models locally (100% free, private, offline)
# Install: https://ollama.com
# Popular models: llama3.1, codellama, mistral, deepseek-coder
OLLAMA_BASE_URL=http://localhost:11434

# LM Studio - Alternative local provider
# Download: https://lmstudio.ai
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ============================================
# üéØ Provider Recommendations by Use Case
# ============================================

# üèÜ Best for ServiceNow Development:
# 1. Anthropic Claude (best reasoning)
# 2. OpenAI GPT-4o (balanced)
# 3. Groq (fastest, free)

# üíµ Most Cost-Effective:
# 1. Ollama (free, local)
# 2. Groq (free with limits)
# 3. OpenRouter/Mistral (cheap)

# üåç Best for Privacy/Compliance:
# 1. Ollama (fully local)
# 2. Azure OpenAI (enterprise SLA)
# 3. Mistral (EU-based)

# üìö Best for Large Contexts:
# 1. Google Gemini (2M tokens)
# 2. Anthropic Claude (200K tokens)
# 3. OpenAI GPT-4o (128K tokens)

# ============================================
# üîß Advanced Provider Configuration
# ============================================

# Custom OpenAI-compatible endpoints
OPENAI_BASE_URL=https://api.openai.com/v1

# Custom headers for providers (optional)
# OPENROUTER_HTTP_REFERER=https://your-app.com
# OPENROUTER_X_TITLE=Snow-Flow

# Rate limiting (requests per minute)
RATE_LIMIT_RPM=60

# ============================================
# OpenCode Configuration
# ============================================

# Model temperature (0.0 - 2.0)
MODEL_TEMPERATURE=1.0

# Max tokens for responses
MODEL_MAX_TOKENS=4096

# Enable auto-confirm for safe operations (use with caution)
AUTO_CONFIRM_SAFE_OPERATIONS=false

# ============================================
# Snow-Flow Configuration
# ============================================

# Log level: debug, info, warn, error
LOG_LEVEL=info

# Enable performance tracking
ENABLE_PERFORMANCE_TRACKING=true

# Enable memory system
ENABLE_MEMORY_SYSTEM=true
